
# ðŸ¤– Jogo da Velha com InteligÃªncia Artificial (DQN)

Este projeto implementa um agente de IA treinado com **Deep Q-Learning (DQN)** para jogar **Tic-Tac-Toe (Jogo da Velha)**. A interface grÃ¡fica Ã© feita com **Tkinter**, e o modelo de rede neural Ã© desenvolvido com **PyTorch**.

---

## ðŸ“‚ Estrutura do Projeto

```

ðŸ“ projeto/
â”œâ”€â”€ main.py             # Ponto de entrada que inicia a aplicaÃ§Ã£o
â”œâ”€â”€ model.py            # Arquitetura da rede neural (TicTacToeNet)
â”œâ”€â”€ agent.py            # ImplementaÃ§Ã£o do agente DQN
â”œâ”€â”€ game.py             # Regras do jogo, verificaÃ§Ã£o de vitÃ³ria e sistema de recompensa
â”œâ”€â”€ ui.py               # Interface grÃ¡fica completa com modos de jogo e treinamento
â”œâ”€â”€ tic_tac_toe_model.pth # Arquivo de modelo salvo
â”œâ”€â”€ README.md           # DocumentaÃ§Ã£o do projeto

````

---

## ðŸ§  Componentes

### ðŸ”¸ `model.py`: Rede Neural (TicTacToeNet)

Modelo com 3 camadas lineares e funÃ§Ãµes de ativaÃ§Ã£o ReLU, responsÃ¡vel por processar o estado do tabuleiro e gerar Q-values para cada aÃ§Ã£o.

```python
Input:  [9]  # Estado do tabuleiro
Output: [9]  # Q-values para cada posiÃ§Ã£o
````

---

### ðŸ”¸ `agent.py`: Agente DQN

ResponsÃ¡vel por:

* Tomar decisÃµes usando polÃ­tica epsilon-greedy
* Treinar com minibatches de um buffer de replay
* Manter uma rede de destino (target network) para maior estabilidade
* Aplicar heurÃ­sticas como movimentos crÃ­ticos

---

### ðŸ”¸ `game.py`: LÃ³gica do Jogo

ContÃ©m funÃ§Ãµes para:

* Validar aÃ§Ãµes possÃ­veis
* Aplicar jogadas
* Verificar vencedor
* Calcular recompensa com base no resultado da partida

---

### ðŸ”¸ `ui.py`: Interface GrÃ¡fica

Interface interativa em Tkinter com suporte para:

* ðŸ§‘ vs ðŸ¤–: Humano contra IA
* ðŸ¤– vs ðŸ¤–: Duelo entre IAs
* ðŸŽ¯ Treinar: Treinamento contÃ­nuo da IA contra ela mesma
* ExibiÃ§Ã£o de estatÃ­sticas e botÃ£o de salvar modelo

---

## ðŸš€ Como Executar

### 1. Instalar dependÃªncias

```bash
pip install torch numpy
```

### 2. Executar o jogo

```bash
python main.py
```

> ObservaÃ§Ã£o: `tkinter` jÃ¡ estÃ¡ incluso na maioria das instalaÃ§Ãµes do Python. Em distribuiÃ§Ãµes Linux minimalistas, instale via pacote `python3-tk`.

---

## ðŸŽ® Modos de Jogo

| Modo       | DescriÃ§Ã£o                                 |
| ---------- | ----------------------------------------- |
| ðŸ§‘ vs ðŸ¤–   | Humano joga contra IA                     |
| ðŸ¤– vs ðŸ¤–   | IA joga contra si mesma                   |
| ðŸŽ¯ Treinar | IA joga partidas aleatÃ³rias para aprender |

---

## ðŸ’¾ Salvamento de Modelo

VocÃª pode salvar o progresso da IA clicando em **ðŸ’¾ Salvar Modelo**. O arquivo `tic_tac_toe_model.pth` serÃ¡ criado ou sobrescrito.

---

## ðŸ“Š EstatÃ­sticas

ExibiÃ§Ã£o em tempo real de:

* Total de jogos
* VitÃ³rias da IA e do humano
* Empates
* Progresso de aprendizado durante o treinamento

---

## ðŸ§ª LÃ³gica de Treinamento

* A IA joga contra si mesma com polÃ­tica epsilon-greedy
* Armazena transiÃ§Ãµes (estado, aÃ§Ã£o, recompensa, novo estado, terminal)
* Executa backpropagation a cada jogo com um minibatch de exemplos

---

## ðŸŽ¯ Sistema de Recompensas

| SituaÃ§Ã£o      | Recompensa |
| ------------- | ---------- |
| VitÃ³ria       | +10        |
| Derrota       | -10        |
| Empate        | +1         |
| Jogo continua | 0          |

---

## ðŸ“¦ Futuras ExtensÃµes

* Double DQN
* Prioritized Experience Replay
* HistÃ³rico visual de partidas
* EstatÃ­sticas de loss e Q-values
* IntegraÃ§Ã£o multiplayer online

---

## ðŸ‘¨â€ðŸ’» Autor

Desenvolvido por **Nikz**

> Deep Learning Research & Applications

